{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GiX007/llm-from-scratch/blob/main/00_tiny_gpt_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building a tiny GPT from Scratch"
      ],
      "metadata": {
        "id": "wJpXpmjEYC_T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we build a character-level language model step by step using PyTorch.\n",
        "Starting from a simple bigram baseline, we progressively introduce batching, context windows, and self-attention, ending with a small Transformer-style model that can generate text."
      ],
      "metadata": {
        "id": "RylJqO9I9EMI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "torch.manual_seed(123)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tTPOsXGoJ5g",
        "outputId": "3f35dc93-7b5c-4125-d4ed-158aa9343aa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7c173416aa70>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get the dataset"
      ],
      "metadata": {
        "id": "KZUUx2CIoiQP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use the **tiny-shakespeare** dataset."
      ],
      "metadata": {
        "id": "z7-E1-PNfk82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read the text dataset into a single Python string\n",
        "with open(\"tiny-shakespeare.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "  text = f.read()"
      ],
      "metadata": {
        "id": "jFIpfRaWes9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inspect the length of our text dataset (number of characters = number of training tokens later)\n",
        "print(\"Dataset length in characters:\", len(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8n5pF48fXgI",
        "outputId": "15cd8d11-c4d1-403b-9dd5-ecae69165ea1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset length in characters: 1115393\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preview the first 1000 characters\n",
        "print(\"\\n--- Dataset preview (first 1000 characters) ---\\n\")\n",
        "print(text[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NReuRwGMfZZb",
        "outputId": "b5275afa-b9e0-4be8-9950-279727436a1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Dataset preview (first 1000 characters) ---\n",
            "\n",
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be done: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor citizens, the patricians good.\n",
            "What authority surfeits on would relieve us: if they\n",
            "would yield us but the superfluity, while it were\n",
            "wholesome, we might guess they relieved us humanely;\n",
            "but they think we are too dear: the leanness that\n",
            "afflicts us, the object of our misery, is as an\n",
            "inventory to particularise their abundance; our\n",
            "sufferance is a gain to them Let us revenge this with\n",
            "our pikes, ere we become rakes: for the gods know I\n",
            "speak this in hunger for bread, not in thirst for revenge.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Character-level Tokenization"
      ],
      "metadata": {
        "id": "XdLwGn4qpqWY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We convert raw text into numbers so it can be processed by a neural network.\n",
        "Here we use a simple character-level tokenizer: each unique character gets an integer ID."
      ],
      "metadata": {
        "id": "u3U-IFdFhOwg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get all unique characters in the dataset\n",
        "chars = sorted(list(set(text)))\n",
        "\n",
        "# vocabulary size = number of unique characters\n",
        "vocab_size = len(chars)\n",
        "\n",
        "# inspect the vocabulary\n",
        "print(''.join(chars))\n",
        "print(\"Vocab size:\", vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e-Rbyr8sfM8",
        "outputId": "4485c797-1879-4227-8577-a083f728260f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
            "Vocab size: 65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# map characters to integers (string → numbers)\n",
        "stoi = {ch: i for i, ch in enumerate(chars)}\n",
        "\n",
        "# map integers back to characters (numbers → string)\n",
        "itos = {i: ch for i, ch in enumerate(chars)}\n",
        "\n",
        "# encoder: string → list of integers\n",
        "encode = lambda s: [stoi[c] for c in s]\n",
        "\n",
        "# decoder: list of integers → string\n",
        "decode = lambda l: ''.join([itos[i] for i in l])\n",
        "\n",
        "# quick sanity check\n",
        "print(encode(\"hii there\"))\n",
        "print(decode(encode(\"hii there\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yw1LKNCgwjj1",
        "outputId": "c37f1861-41b6-418c-dd71-c269e5d441d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[46, 47, 47, 1, 58, 46, 43, 56, 43]\n",
            "hii there\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# encode the entire dataset as a tensor of token IDs\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "\n",
        "# inspect shape and type\n",
        "print(data.shape, data.dtype)\n",
        "\n",
        "# preview first tokens\n",
        "print(data[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJb0OXPwzvqg",
        "outputId": "497d7c69-7e01-49ab-a5aa-2f3b647c40b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1115393]) torch.int64\n",
            "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
            "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
            "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
            "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
            "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
            "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
            "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
            "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
            "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
            "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
            "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
            "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
            "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
            "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
            "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
            "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
            "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
            "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
            "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
            "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
            "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
            "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
            "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
            "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
            "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
            "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
            "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
            "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
            "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
            "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
            "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
            "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
            "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
            "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
            "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
            "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
            "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
            "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
            "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
            "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
            "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
            "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
            "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
            "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
            "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
            "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
            "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
            "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
            "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
            "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
            "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
            "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
            "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
            "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
            "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
            "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This tokenizer is intentionally simple.\n",
        "Modern LLMs use subword tokenizers (e.g., titokenizer, see https://tiktokenizer.vercel.app/), but character-level models are ideal for learning core concepts."
      ],
      "metadata": {
        "id": "eraPKaz1i0vb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Sequences: Inputs and Targets"
      ],
      "metadata": {
        "id": "pC0sO1mUqqyq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We split the tokenized data into training and validation sets.\n",
        "Then we build fixed-length input sequences and their next-token targets for language modeling."
      ],
      "metadata": {
        "id": "5jbu_4e8kiHk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split data into train and validation sets\n",
        "n = int(0.9 * len(data)) # 90% train, 10% validation\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]"
      ],
      "metadata": {
        "id": "f_WIXqxz0lU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# block_size = number of tokens the model can see (context window)\n",
        "block_size = 8\n",
        "\n",
        "# inspect one chunk (+1 for target shift)\n",
        "print(train_data[:block_size + 1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TD5Bj8Y6IAD4",
        "outputId": "30733ad3-e498-47b2-d421-2d02bdd7d237"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# input tokens\n",
        "x = train_data[:block_size]\n",
        "\n",
        "# target tokens (shifted by one)\n",
        "y = train_data[1:block_size + 1]\n",
        "\n",
        "# show how each position predicts the next token\n",
        "for t in range(block_size):\n",
        "  context = x[:t + 1]\n",
        "  target = y[t]\n",
        "  print(f\"when input is {context}, the target: {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HXDe8vGJCEn",
        "outputId": "a99b6951-fec7-4f0d-bb30-0b8849111aa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when input is tensor([18]), the target: 47\n",
            "when input is tensor([18, 47]), the target: 56\n",
            "when input is tensor([18, 47, 56]), the target: 57\n",
            "when input is tensor([18, 47, 56, 57]), the target: 58\n",
            "when input is tensor([18, 47, 56, 57, 58]), the target: 1\n",
            "when input is tensor([18, 47, 56, 57, 58,  1]), the target: 15\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15]), the target: 47\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]), the target: 58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# batch generation\n",
        "batch_size = 4 # how many independent sequences will we process in parallel (number of sequences per batch)\n",
        "block_size = 8 # context length\n",
        "\n",
        "# data loading\n",
        "def get_batch(split):\n",
        "  # select train or validation data\n",
        "  data_split = train_data if split == \"train\" else val_data\n",
        "\n",
        "  # randomly choose starting positions\n",
        "  ix = torch.randint(len(data_split) - block_size, (batch_size,))\n",
        "\n",
        "  # build input and target batches\n",
        "  x = torch.stack([data[i:i+block_size] for i in ix]) # stack all vectors into rows\n",
        "  y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "\n",
        "  return x, y\n",
        "\n",
        "xb, yb = get_batch(\"train\")\n",
        "print(\"inputs:\")\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "\n",
        "print(\"\\ntargets:\")\n",
        "print(yb.shape)\n",
        "print(yb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3k1Czf7LuA9",
        "outputId": "ed455658-e83a-4f12-da1c-f8656b541ab3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs:\n",
            "torch.Size([4, 8])\n",
            "tensor([[59, 56,  6,  1, 46, 39, 58, 46],\n",
            "        [53, 56, 40, 47, 42,  1, 53, 59],\n",
            "        [41, 43,  0, 32, 39, 49, 43,  1],\n",
            "        [27, 30, 23, 10,  0, 20, 47, 57]])\n",
            "\n",
            "targets:\n",
            "torch.Size([4, 8])\n",
            "tensor([[56,  6,  1, 46, 39, 58, 46,  1],\n",
            "        [56, 40, 47, 42,  1, 53, 59, 56],\n",
            "        [43,  0, 32, 39, 49, 43,  1, 53],\n",
            "        [30, 23, 10,  0, 20, 47, 57,  1]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show how every token predicts the next one (per batch element)\n",
        "for b in range(batch_size):\n",
        "  for t in range(block_size):\n",
        "    context = xb[b, :t+1]\n",
        "    target = yb[b,t]\n",
        "    print(f\"when input is {context.tolist()} the target: {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bjbrsj3vmTZ3",
        "outputId": "b940f2b1-648b-441a-8318-a76f23b5ac9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when input is [59] the target: 56\n",
            "when input is [59, 56] the target: 6\n",
            "when input is [59, 56, 6] the target: 1\n",
            "when input is [59, 56, 6, 1] the target: 46\n",
            "when input is [59, 56, 6, 1, 46] the target: 39\n",
            "when input is [59, 56, 6, 1, 46, 39] the target: 58\n",
            "when input is [59, 56, 6, 1, 46, 39, 58] the target: 46\n",
            "when input is [59, 56, 6, 1, 46, 39, 58, 46] the target: 1\n",
            "when input is [53] the target: 56\n",
            "when input is [53, 56] the target: 40\n",
            "when input is [53, 56, 40] the target: 47\n",
            "when input is [53, 56, 40, 47] the target: 42\n",
            "when input is [53, 56, 40, 47, 42] the target: 1\n",
            "when input is [53, 56, 40, 47, 42, 1] the target: 53\n",
            "when input is [53, 56, 40, 47, 42, 1, 53] the target: 59\n",
            "when input is [53, 56, 40, 47, 42, 1, 53, 59] the target: 56\n",
            "when input is [41] the target: 43\n",
            "when input is [41, 43] the target: 0\n",
            "when input is [41, 43, 0] the target: 32\n",
            "when input is [41, 43, 0, 32] the target: 39\n",
            "when input is [41, 43, 0, 32, 39] the target: 49\n",
            "when input is [41, 43, 0, 32, 39, 49] the target: 43\n",
            "when input is [41, 43, 0, 32, 39, 49, 43] the target: 1\n",
            "when input is [41, 43, 0, 32, 39, 49, 43, 1] the target: 53\n",
            "when input is [27] the target: 30\n",
            "when input is [27, 30] the target: 23\n",
            "when input is [27, 30, 23] the target: 10\n",
            "when input is [27, 30, 23, 10] the target: 0\n",
            "when input is [27, 30, 23, 10, 0] the target: 20\n",
            "when input is [27, 30, 23, 10, 0, 20] the target: 47\n",
            "when input is [27, 30, 23, 10, 0, 20, 47] the target: 57\n",
            "when input is [27, 30, 23, 10, 0, 20, 47, 57] the target: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# example model input\n",
        "print(xb.shape)\n",
        "print(xb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpyyAeIzQjlO",
        "outputId": "9a7f862b-4a41-4650-bc90-e7532244fd40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 8])\n",
            "tensor([[59, 56,  6,  1, 46, 39, 58, 46],\n",
            "        [53, 56, 40, 47, 42,  1, 53, 59],\n",
            "        [41, 43,  0, 32, 39, 49, 43,  1],\n",
            "        [27, 30, 23, 10,  0, 20, 47, 57]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each input sequence is trained to predict the next token at every position.\n",
        "This is the core supervision signal used to train autoregressive language models."
      ],
      "metadata": {
        "id": "ett9mRUfmkfP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bigram Language Model (Baseline)"
      ],
      "metadata": {
        "id": "98v7_u7is_1R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We start with a very small baseline: a *bigram* language model.\n",
        "It predicts the next token using only the current token (no attention, no context mixing)."
      ],
      "metadata": {
        "id": "wCAisRZ1nynF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# predicts next token using only the current token (the simplest NN)\n",
        "class BigramLanguageModel(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size):\n",
        "    super().__init__()\n",
        "    # lookup table: token_id -> logits over next token\n",
        "    self.token_embedding_table = nn.Embedding(vocab_size, vocab_size) # (C, C)\n",
        "\n",
        "  def forward(self, idx, targets=None):\n",
        "    # idx: (B, T) -> logits: (B, T, C), B for batch size, T (Time) for context length, C (Channels) for vocab size\n",
        "    logits = self.token_embedding_table(idx)\n",
        "\n",
        "    loss = None\n",
        "    if targets is not None:\n",
        "      B, T, C = logits.shape\n",
        "      logits = logits.view(B * T, C)\n",
        "      targets = targets.view(B * T)\n",
        "      loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "    return logits, loss\n",
        "\n",
        "  def generate(self, idx, max_new_tokens):\n",
        "    for _ in range(max_new_tokens):\n",
        "      logits, loss = self(idx) # get the predictions\n",
        "      logits = logits[:, -1, :] # focus only on the last time step, it becomes (B, C)\n",
        "      probs = F.softmax(logits, dim=-1) # next-token distribution, (B, C)\n",
        "      idx_next = torch.multinomial(probs, num_samples=1) # sample from the distribution, (B, 1)\n",
        "      idx = torch.cat((idx, idx_next), dim=1) # append sampled index to the running sequence, (B, T+1)\n",
        "    return idx"
      ],
      "metadata": {
        "id": "nql_1ER53oCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# forward pass for sanity check\n",
        "m = BigramLanguageModel(vocab_size)\n",
        "logits, loss = m(xb, yb)\n",
        "\n",
        "print(logits.shape)\n",
        "print(loss)"
      ],
      "metadata": {
        "id": "pRy60CxCtJ7P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3057c9ee-8e4a-472b-bb77-6467ba7ba7e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 65])\n",
            "tensor(4.6669, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate before training\n",
        "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4Diz2KQFrkB",
        "outputId": "d9a33d52-4296-4334-db2a-1382ad3e90d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MuD&sYMZTlXMP?HZTnJfpsh&omS$ApW3zEYQ&rrvjhGy?AYvB;'ECISU\n",
            "xTA\n",
            "vCNhscX;aiXMHnk,TPI;D?f&Fb&FZblxzqi.abd\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model (few steps, educational)\n",
        "\n",
        "# optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "for steps in range(100):\n",
        "  xb, yb = get_batch('train')\n",
        "\n",
        "  logits, loss = m(xb, yb)\n",
        "\n",
        "  optimizer.zero_grad(set_to_none=True)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hs4kI8YdEkQj",
        "outputId": "92cd36b0-5971-4e51-9d8d-8d10ea6ccdc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.593630790710449\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate after training\n",
        "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcVIDWAZEtjN",
        "outputId": "3799c2a7-6b0e-41f2-832e-f4cdc495714a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ":SSqd,tvmXQh:R&hcheHMuxmXdgoNWVa,HHuA\n",
            "Fhs;aVkGcwvNnwlx?&3-J3zqAo3ihKHKn?HSlf3bHj'v$hbROpQSwwTkXcGn,H,AVtetlzD:YorwTpFPHvLmPzB;ZTzUETq\n",
            "ZDJ.-WawbH w-GOAdmvCjKmwosn..WGjDca&sca,J$3h-F'w\n",
            "3oIxpYH,FEZ;lOVY:S$d!GJVCgfVDAnwyhkdT wlfaRHyDNsP!cjhheAEIwG'MPH,H3goJ&QQxKG3&sIBtPHj$-nuZEoZCVA'D-wLZhKJ\n",
            "3$?IgImxKp'etpYYe..a:o w wa&d$gJCaCvxU?ub\n",
            " WjAlaZO H-dnOLYoaUHHKZDTI!cjvvlrQysn\n",
            "x weiiXdfAJPefreoB-dUvvBbJOV;,ECAYHdXCK?uL\n",
            "'Tw$!eih\n",
            "B\n",
            "FhWfYxHa w FKddxu!mvFRk' VPHuhcyBTX!vn-Xrs;UvWVYK;3iMsCEkTzNauFa$TXTB\n",
            "\n",
            ":uwqXK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model is a strong “hello world”: it learns token-to-token transitions.\n",
        "Next we'll upgrade it to use context via attention."
      ],
      "metadata": {
        "id": "lEklOVe9quyR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The math behind self-attention"
      ],
      "metadata": {
        "id": "XinV8nmAnmKN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The bigram model only looks at the current token, which severely limits what it can learn. To model longer dependencies, we need a mechanism that lets tokens communicate and share information across the sequence.\n",
        "Self-attention provides exactly this.\n",
        "\n",
        "Self-attention lets tokens “communicate”: each token builds a weighted summary of earlier tokens.\n",
        "Before we implement attention, we'll learn the core trick: masked weighted averaging via matrix multiplication.\n",
        "\n",
        "**Goal:** allow each token position `t` to combine information from tokens `≤ t` (causal / autoregressive)."
      ],
      "metadata": {
        "id": "7lUnXdIfs005"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# toy example: matrix multiplication as a weighted sum of rows (weighted aggregation)\n",
        "# tril() makes it causal (only current + previous)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "a = torch.tril(torch.ones(3, 3))\n",
        "a = a / torch.sum(a, 1, keepdim=True) # normalize rows -> weights sum to 1\n",
        "\n",
        "b = torch.randint(0, 10, (3, 2)).float() # \"values\" to aggregate\n",
        "c = a @ b # weighted average\n",
        "\n",
        "print('a='); print(a); print()\n",
        "print('b='); print(b); print()\n",
        "print('c='); print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tukiH-NbRBhA",
        "outputId": "43ecfdba-27dc-441e-94f1-2e70d0f6906f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a=\n",
            "tensor([[1.0000, 0.0000, 0.0000],\n",
            "        [0.5000, 0.5000, 0.0000],\n",
            "        [0.3333, 0.3333, 0.3333]])\n",
            "\n",
            "b=\n",
            "tensor([[2., 7.],\n",
            "        [6., 4.],\n",
            "        [6., 5.]])\n",
            "\n",
            "c=\n",
            "tensor([[2.0000, 7.0000],\n",
            "        [4.0000, 5.5000],\n",
            "        [4.6667, 5.3333]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each row of `a` controls how much information is taken from earlier rows of `b`.\n",
        "Because of causal masking, position `t` cannot use future information (`> t`), so averaging allows each token to combine information from all previous tokens in a causal way."
      ],
      "metadata": {
        "id": "dvIp9sFguIAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To make this concrete, we'll work with a small toy batch.\n",
        "Each sequence contains a few tokens, and each token is represented by a simple feature vector."
      ],
      "metadata": {
        "id": "1d3yemfUuv2t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a toy sequence batch of: B sequences, each of length T, each token has C features\n",
        "B,T,C = 4, 8, 2\n",
        "x = torch.randn(B, T, C)\n",
        "\n",
        "print(x.shape)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hs_E24uRE8kr",
        "outputId": "ee81d816-fbfb-4ba3-b5c7-1abd3e85e468"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 8, 2])\n",
            "tensor([[[-0.0431, -1.6047],\n",
            "         [ 1.7878, -0.4780],\n",
            "         [-0.2429, -0.9342],\n",
            "         [-0.2483, -1.2082],\n",
            "         [-0.7688,  0.7624],\n",
            "         [-1.5673, -0.2394],\n",
            "         [ 2.3228, -0.9634],\n",
            "         [ 2.0024,  0.4664]],\n",
            "\n",
            "        [[ 0.8008,  1.6806],\n",
            "         [ 0.3559, -0.6866],\n",
            "         [-0.4934,  0.2415],\n",
            "         [-1.1109,  0.0915],\n",
            "         [-0.2516,  0.8599],\n",
            "         [-0.3097, -0.3957],\n",
            "         [ 0.8034, -0.6216],\n",
            "         [-0.5920, -0.0631]],\n",
            "\n",
            "        [[ 0.3057, -0.7746],\n",
            "         [ 0.0349,  0.3211],\n",
            "         [ 1.5736, -0.8455],\n",
            "         [ 1.3123,  0.6872],\n",
            "         [-1.2347, -0.4879],\n",
            "         [-1.4181,  0.8963],\n",
            "         [ 0.0499,  2.2667],\n",
            "         [ 1.1790, -0.4345]],\n",
            "\n",
            "        [[-0.8140, -0.7360],\n",
            "         [-0.8371, -0.9224],\n",
            "         [ 1.8113,  0.1606],\n",
            "         [ 0.3672,  0.1754],\n",
            "         [-1.1845,  1.3835],\n",
            "         [-1.2024,  0.7078],\n",
            "         [-1.0759,  0.5357],\n",
            "         [ 1.1754,  0.5612]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Explicit averaging over previous tokens"
      ],
      "metadata": {
        "id": "-8aIjREhvIJG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# goal: xbow[b,t] = mean_{i<=t} x[b,i]\n",
        "xbow = torch.zeros((B,T,C)) # bow from bag of words\n",
        "\n",
        "for b in range(B):\n",
        "  for t in range(T):\n",
        "    xprev = x[b,:t+1] # tokens up to t, (t, C)\n",
        "    xbow[b,t] = torch.mean(xprev, 0) # mean over time"
      ],
      "metadata": {
        "id": "86NuXX0fn7ps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuDlXVRALsIb",
        "outputId": "1efd7efb-fee0-4484-9a29-f8bbec2379f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0431, -1.6047],\n",
            "        [ 1.7878, -0.4780],\n",
            "        [-0.2429, -0.9342],\n",
            "        [-0.2483, -1.2082],\n",
            "        [-0.7688,  0.7624],\n",
            "        [-1.5673, -0.2394],\n",
            "        [ 2.3228, -0.9634],\n",
            "        [ 2.0024,  0.4664]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(xbow[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygCPGlEeLu-L",
        "outputId": "dd38fda3-5766-42f6-8ecb-d781a0a9dd3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0431, -1.6047],\n",
            "        [ 0.8724, -1.0414],\n",
            "        [ 0.5006, -1.0056],\n",
            "        [ 0.3134, -1.0563],\n",
            "        [ 0.0970, -0.6925],\n",
            "        [-0.1804, -0.6170],\n",
            "        [ 0.1772, -0.6665],\n",
            "        [ 0.4053, -0.5249]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice how `xbow[0, t]` is the average of `x[0, 0:t+1]`.\n"
      ],
      "metadata": {
        "id": "V9QM4mfUL076"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Efficient averaging via matrix multiplication"
      ],
      "metadata": {
        "id": "Mkdi8pfmv5Ym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# build causal averaging weights (T x T)\n",
        "wei = torch.tril(torch.ones(T, T))\n",
        "wei = wei / wei.sum(1, keepdim=True) # row-normalize\n",
        "\n",
        "# (T, T) @ (B, T, C) -> (B, T, C) via broadcasting\n",
        "xbow2 = wei @ x\n",
        "\n",
        "torch.allclose(xbow, xbow2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzCMWVnCvjT3",
        "outputId": "e939d11a-0195-4678-bf63-3f33ec61f6bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Softmax-based causal weighting"
      ],
      "metadata": {
        "id": "IYYMRMYqv_1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# softmax turns scores into probabilities\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "\n",
        "wei = torch.zeros((T,T))\n",
        "wei = wei.masked_fill(tril == 0, float('-inf')) # block future positions\n",
        "print(wei)\n",
        "\n",
        "wei = F.softmax(wei, dim=-1) # row sums to 1\n",
        "print(wei)\n",
        "\n",
        "xbow3 = wei @ x\n",
        "torch.allclose(xbow, xbow3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOURrfG-ysoL",
        "outputId": "ab41ecba-ddca-4e4a-f345-9ceee1631717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
            "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
            "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
            "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So far, the weights are *fixed* (not learned, not data-dependent).\n",
        "Self-attention makes these weights depend on the token content."
      ],
      "metadata": {
        "id": "LvuklStXz4ks"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Learned, data-dependent weighting (self-attention)"
      ],
      "metadata": {
        "id": "sM7ROyWxzVTq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Self-attention intuition**\n",
        "\n",
        "Each token decides how much to attend to other tokens based on their content.\n",
        "This is done by comparing what a token is looking for with what other tokens contain.\n",
        "\n",
        "Each token produces three vectors:\n",
        "- **Query (Q):** what I am looking for\n",
        "- **Key (K):** what I contain\n",
        "- **Value (V):** the information I provide\n",
        "\n",
        "Attention weights are computed from query-key similarity and used to mix values.\n",
        "\n",
        "At each position:\n",
        "1. compute similarity scores between queries and keys\n",
        "2. apply causal masking to block future tokens\n",
        "3. normalize scores with softmax\n",
        "4. use the weights to aggregate values\n"
      ],
      "metadata": {
        "id": "O2bfr6V90r8e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Self-attention (single head)."
      ],
      "metadata": {
        "id": "m8yN6hWm1Lar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# self-attention with learned, data-dependent weights\n",
        "B, T, C = 4, 8, 32 # batch, time, channels\n",
        "x = torch.randn(B, T, C)\n",
        "\n",
        "head_size = 16\n",
        "\n",
        "key = nn.Linear(C, head_size, bias=False)\n",
        "query = nn.Linear(C, head_size, bias=False)\n",
        "value = nn.Linear(C, head_size, bias=False)\n",
        "\n",
        "k = key(x) # (B, T, head_size)\n",
        "q = query(x) # (B, T, head_size)\n",
        "\n",
        "# attention scores\n",
        "wei =  q @ k.transpose(-2, -1) # (B, T, head_size) @ (B, head_size, T) ---> (B, T, T)\n",
        "\n",
        "# causal mask (decoder-style)\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "wei = F.softmax(wei, dim=-1) # normalize\n",
        "\n",
        "# aggreagate values\n",
        "v = value(x) # (B, T, head_size)\n",
        "out = wei @ v # (B, T, head_size)"
      ],
      "metadata": {
        "id": "EDarxEWIRMKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display the output\n",
        "print(out.shape)\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STi-8XUh1x0B",
        "outputId": "8dad510b-a29f-4802-a130-8197c328b821"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 8, 16])\n",
            "tensor([[[ 1.2309e+00, -5.8830e-01,  8.3699e-02, -2.4703e-01,  5.7573e-02,\n",
            "          -1.2661e+00,  1.3852e-01,  8.2426e-01,  1.2837e-02, -2.9015e-01,\n",
            "           2.6208e-01,  3.7443e-01,  6.7970e-01,  5.9684e-01,  3.1133e-01,\n",
            "          -4.7922e-01],\n",
            "         [ 7.4428e-01, -2.3934e-02, -6.6331e-02, -3.7515e-02,  3.5757e-02,\n",
            "          -3.4072e-01,  2.2588e-01,  4.4565e-01,  3.7820e-02,  2.1374e-01,\n",
            "           6.0595e-01,  2.6574e-01,  2.4792e-01,  4.7638e-01, -1.4091e-01,\n",
            "           2.7625e-01],\n",
            "         [ 4.3012e-01, -3.1783e-02,  1.4615e-01, -3.6217e-01, -2.1957e-01,\n",
            "          -1.4638e-01, -5.8746e-01,  1.2682e-01, -5.6536e-02,  2.9793e-01,\n",
            "          -1.8272e-01,  6.8918e-02,  1.8934e-01,  5.2959e-01, -4.0646e-02,\n",
            "          -2.5657e-02],\n",
            "         [ 3.7924e-01,  1.3171e-03,  1.5383e-01, -4.3043e-01, -2.2283e-01,\n",
            "          -1.5539e-01, -5.5159e-01,  8.2522e-02, -1.0567e-01,  2.8703e-01,\n",
            "          -8.5874e-02,  1.3697e-02,  5.1500e-02,  4.9496e-01, -9.5157e-02,\n",
            "           4.6695e-02],\n",
            "         [ 2.3887e-01,  1.0778e-02, -1.9374e-01, -2.9278e-01,  2.4374e-02,\n",
            "          -3.7673e-01, -5.7554e-01, -9.9882e-02, -4.7178e-01, -7.0277e-02,\n",
            "           5.4216e-01, -4.4250e-01, -3.3838e-01,  5.3644e-01, -1.8032e-02,\n",
            "           9.5775e-02],\n",
            "         [ 2.8778e-01, -2.2054e-01, -2.6880e-01, -1.5249e-03, -5.0123e-02,\n",
            "          -4.4230e-02, -1.4680e-01,  3.2639e-01, -7.9932e-02,  3.9614e-01,\n",
            "           2.6652e-01, -4.2106e-01,  1.5285e-01,  1.0343e-01, -2.1997e-01,\n",
            "           2.9322e-01],\n",
            "         [ 1.0022e-01, -8.2260e-02,  1.0997e-02, -1.6209e-01,  4.3414e-03,\n",
            "          -3.6733e-01, -3.3991e-01,  1.7635e-01, -1.5260e-01,  2.1507e-01,\n",
            "           1.6577e-01, -1.7855e-01,  1.1509e-02,  5.8672e-01,  7.6387e-02,\n",
            "          -5.6855e-02],\n",
            "         [ 3.7779e-01, -2.5676e-01, -1.6099e-01,  1.6709e-01,  7.3983e-02,\n",
            "          -1.9720e-02,  2.8384e-01,  3.2253e-01,  1.4460e-01,  7.0784e-02,\n",
            "           2.1692e-01, -3.5142e-01,  2.3367e-01, -8.3989e-02, -2.1738e-01,\n",
            "           5.2288e-02]],\n",
            "\n",
            "        [[-2.0015e-01,  4.5774e-01, -2.9076e-01,  5.1886e-02, -1.4284e-01,\n",
            "           6.6329e-02,  3.5565e-01, -3.0234e-01,  3.9097e-02, -2.2812e-01,\n",
            "           6.4370e-01,  5.7878e-02, -5.4089e-01, -1.1107e-01, -3.6583e-01,\n",
            "           5.3784e-01],\n",
            "         [-4.6422e-01,  1.7381e-01, -3.7710e-01,  2.4118e-02, -9.4125e-02,\n",
            "          -4.4503e-01, -1.2765e-01, -1.6107e-02, -1.8582e-01, -3.3808e-01,\n",
            "           3.9203e-01, -4.7270e-01, -5.3386e-01, -1.5117e-01, -2.6852e-01,\n",
            "           9.4015e-02],\n",
            "         [-7.5089e-01,  1.4447e-01,  1.7531e-01, -4.2586e-01, -3.9192e-01,\n",
            "          -2.9460e-01,  1.6532e-01, -3.6348e-01, -2.5678e-01, -5.6847e-01,\n",
            "          -6.0189e-02,  2.4752e-02, -2.0448e-01,  8.0197e-02, -1.4321e-02,\n",
            "          -2.0721e-01],\n",
            "         [-1.6982e-01,  2.2582e-01, -6.7359e-02, -1.7297e-01, -1.4766e-01,\n",
            "          -2.8427e-01,  1.0988e-01, -7.5099e-02, -1.5730e-02, -7.5248e-02,\n",
            "           4.9754e-01,  2.2575e-01, -1.5241e-01, -1.2992e-01, -2.0907e-01,\n",
            "           3.2381e-01],\n",
            "         [-3.1865e-01,  3.2100e-01, -1.6861e-01, -6.2188e-02, -3.5518e-01,\n",
            "          -1.7069e-01,  1.9199e-01, -1.7792e-01,  1.7566e-02, -1.5569e-01,\n",
            "           3.2010e-01,  2.4455e-02, -2.4882e-01,  1.1814e-01, -2.2884e-01,\n",
            "           1.8234e-01],\n",
            "         [ 1.3271e-01,  3.4275e-01, -5.2455e-01,  3.3573e-01, -4.7845e-01,\n",
            "          -3.6302e-01, -6.5277e-03,  3.8605e-01,  3.9928e-01,  5.7181e-01,\n",
            "           5.0609e-01, -5.2210e-02, -3.9919e-03,  3.3226e-01, -4.1262e-01,\n",
            "           3.0740e-01],\n",
            "         [ 1.3767e-01,  9.4425e-02,  1.8534e-01, -3.1622e-01, -2.1601e-01,\n",
            "          -4.9606e-01,  3.1893e-02,  2.4675e-01,  1.7218e-01,  4.1004e-01,\n",
            "           4.9407e-01,  7.4028e-01,  4.3438e-01, -1.0565e-01, -1.2100e-01,\n",
            "           3.2178e-01],\n",
            "         [-1.5033e-01,  9.2540e-02,  6.8346e-02, -1.2001e-01, -2.0100e-01,\n",
            "          -4.8192e-01,  5.6214e-02,  2.6782e-01,  1.1534e-01,  1.6057e-01,\n",
            "           3.2157e-01,  3.2775e-01,  1.9407e-01, -9.6972e-02, -1.0780e-01,\n",
            "           6.6562e-02]],\n",
            "\n",
            "        [[ 1.6148e-01,  3.3352e-01, -4.3803e-01,  9.3979e-03, -6.3262e-01,\n",
            "          -1.2977e+00,  6.3353e-02, -8.3932e-02, -1.8440e-01, -5.4764e-01,\n",
            "          -4.8788e-02, -7.3416e-01, -3.4082e-01, -1.4207e-01,  7.1496e-01,\n",
            "           3.0203e-01],\n",
            "         [-7.4693e-03,  9.7423e-02, -4.4126e-01, -1.4500e-01, -4.3188e-01,\n",
            "          -9.2385e-01, -1.0564e-01, -1.9147e-01, -1.3872e-01, -2.6477e-01,\n",
            "           3.6295e-02, -5.3684e-01, -2.2876e-01, -8.3982e-02,  4.6302e-01,\n",
            "           2.6809e-01],\n",
            "         [-4.3811e-01, -3.0655e-01, -3.0491e-01, -2.1335e-01, -5.8481e-02,\n",
            "           2.1588e-01, -3.4862e-01, -4.9291e-01,  1.0612e-01,  4.6789e-01,\n",
            "           1.9362e-01,  2.1814e-01,  2.3710e-01, -9.2598e-02, -2.3834e-01,\n",
            "           1.1318e-01],\n",
            "         [ 5.8210e-01, -3.5519e-01, -4.9691e-01, -2.1394e-01,  1.9841e-02,\n",
            "          -3.2782e-01, -6.6419e-01,  2.9714e-01, -3.0010e-01,  1.8307e-01,\n",
            "           2.0787e-01, -4.1102e-01, -5.9615e-01,  3.7373e-02,  7.2068e-02,\n",
            "           6.3616e-01],\n",
            "         [ 1.5955e-01, -1.3233e-01, -2.7495e-01, -1.1578e-02, -1.4619e-01,\n",
            "          -1.9838e-01, -5.6475e-01, -5.5506e-03, -1.2796e-01,  1.8007e-01,\n",
            "          -9.3773e-03, -2.1564e-01, -2.0346e-01, -2.1125e-01,  9.1566e-02,\n",
            "           5.1991e-01],\n",
            "         [ 1.0505e-01, -3.4298e-01, -2.9248e-01, -2.9213e-01,  3.1710e-02,\n",
            "          -4.0505e-04, -7.0501e-01, -3.8779e-02, -1.5758e-01,  3.6238e-01,\n",
            "           7.1537e-02, -1.7404e-01, -2.8736e-01, -1.1044e-01, -5.7661e-02,\n",
            "           5.2859e-01],\n",
            "         [ 2.5757e-03,  4.0996e-03,  1.0038e-01, -2.3320e-01, -2.3418e-01,\n",
            "           2.5861e-02, -1.8313e-01, -7.2920e-02, -4.6781e-02,  1.5183e-01,\n",
            "          -1.1518e-01,  7.6646e-02, -3.3670e-01, -2.8718e-01,  3.4306e-02,\n",
            "           2.3384e-01],\n",
            "         [-2.6000e-01,  6.9318e-02,  1.3148e-01,  1.2025e-01, -2.9809e-01,\n",
            "           1.3716e-02,  3.9035e-02, -1.5369e-01,  8.3504e-02,  6.8083e-02,\n",
            "          -1.1545e-01,  3.8454e-01,  9.2572e-02, -2.9295e-01,  4.1970e-02,\n",
            "          -8.8174e-02]],\n",
            "\n",
            "        [[-5.2471e-01,  4.8698e-01,  2.2067e-01,  3.7193e-01,  8.8839e-01,\n",
            "           4.6400e-01, -1.7021e-01, -4.0545e-01, -1.0352e+00, -4.9464e-02,\n",
            "           5.4462e-01, -3.6532e-01,  6.4488e-02, -3.1086e-01, -2.7082e-01,\n",
            "          -2.1648e-01],\n",
            "         [-5.8000e-01,  4.0613e-01,  1.9196e-01,  4.0247e-01,  9.4958e-01,\n",
            "           4.0780e-01, -3.3114e-01, -3.2256e-01, -8.4251e-01,  1.4908e-01,\n",
            "           4.0751e-01, -1.5512e-01,  2.7821e-01, -6.9806e-02, -1.7218e-01,\n",
            "          -1.0956e-01],\n",
            "         [ 3.6911e-01, -1.2710e-01, -2.8512e-01,  4.3429e-01, -1.4619e-01,\n",
            "          -1.3671e-01,  7.8560e-01, -4.0908e-01, -2.5264e-01, -1.4623e-01,\n",
            "           5.3479e-01, -1.5565e-01, -7.0491e-01, -2.6168e-01,  8.4610e-01,\n",
            "           1.9052e-01],\n",
            "         [ 2.4205e-01,  4.1435e-02, -1.7226e-01,  5.2383e-01,  1.4785e-01,\n",
            "          -5.8661e-02,  4.7168e-01, -3.1119e-01, -3.6623e-01, -1.4508e-01,\n",
            "           4.6915e-01, -7.2750e-02, -3.1048e-01, -1.1473e-01,  6.4469e-01,\n",
            "           1.8372e-01],\n",
            "         [-3.7423e-01,  6.0074e-02, -5.5630e-02,  5.0064e-01,  7.1629e-01,\n",
            "           2.2657e-02, -4.4720e-01, -1.0176e-01, -7.4727e-02,  6.1755e-01,\n",
            "           1.6536e-02,  4.7705e-01,  6.2740e-01,  6.2121e-01,  4.3647e-01,\n",
            "           3.4690e-01],\n",
            "         [ 2.7066e-01,  2.3189e-01,  1.5478e-01,  1.7810e-01, -2.3030e-02,\n",
            "          -1.6042e-02,  9.6305e-02, -5.3878e-02, -3.8725e-01, -5.7606e-02,\n",
            "          -1.9803e-02, -2.9698e-01,  3.5232e-02, -4.3321e-02,  2.1234e-01,\n",
            "           1.7429e-01],\n",
            "         [ 8.5128e-02, -1.3382e-01,  3.3905e-01, -1.9078e-02,  1.1503e-01,\n",
            "          -2.8912e-02, -1.0872e-02,  2.5038e-01, -1.7840e-01, -5.8806e-02,\n",
            "          -2.5325e-01, -2.8252e-01,  2.0202e-01, -8.9762e-02,  2.1238e-01,\n",
            "          -5.4918e-02],\n",
            "         [-3.2464e-01, -2.2831e-01,  3.5467e-01,  4.3529e-02,  5.9445e-01,\n",
            "          -1.3002e-01, -9.8079e-02,  2.7908e-01,  1.4059e-01, -6.0414e-02,\n",
            "          -1.7292e-01,  1.6035e-01,  5.8163e-01, -6.3690e-03,  2.3428e-01,\n",
            "          -1.0926e-01]]], grad_fn=<UnsafeViewBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inspect attention weights for one example\n",
        "print(wei[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vT1hdtzXCjgL",
        "outputId": "fb3c78b9-c40b-49c5-dd2d-cbc297086177"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.3131, 0.6869, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.3071, 0.1665, 0.5264, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2865, 0.1539, 0.4501, 0.1096, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0935, 0.1449, 0.1449, 0.2585, 0.3581, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0685, 0.1716, 0.0297, 0.0232, 0.2059, 0.5010, 0.0000, 0.0000],\n",
            "        [0.1452, 0.0654, 0.2293, 0.0887, 0.1483, 0.1025, 0.2206, 0.0000],\n",
            "        [0.0633, 0.0456, 0.0105, 0.0078, 0.1231, 0.3747, 0.0454, 0.3295]],\n",
            "       grad_fn=<SelectBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attention is a communication mechanism: each token aggregates information from other tokens using learned weights.\n",
        "\n",
        "There is no notion of order in attention itself, which is why positional information must be added separately.\n",
        "\n",
        "Each sequence in the batch is processed independently and never \"talk\" to each other.\n",
        "\n",
        "Causal masking makes this a decoder-style attention block, suitable for autoregressive language modeling."
      ],
      "metadata": {
        "id": "Wd-LTikC2E6F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scaling by `1 / sqrt(head_size)` keeps attention scores at a reasonable scale.\n",
        "This prevents softmax from becoming too sharp as the embedding dimension grows."
      ],
      "metadata": {
        "id": "zMcieCbu3cOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k = torch.randn(B, T, head_size)\n",
        "q = torch.randn(B, T, head_size)\n",
        "print(k.var(), q.var())\n",
        "\n",
        "# unscaled dot-product attention\n",
        "wei = q @ k.transpose(-2, -1)  # (B, T, T)\n",
        "print(wei.var())\n",
        "\n",
        "# scaled dot-product attention\n",
        "wei = q @ k.transpose(-2, -1) * head_size**-0.5\n",
        "print(wei.var())"
      ],
      "metadata": {
        "id": "4SNbLq5z3oBw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db834275-635c-49be-b394-ea46f38391dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.0116) tensor(0.9358)\n",
            "tensor(14.3098)\n",
            "tensor(0.8944)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# softmax behavior example\n",
        "print(torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5]), dim=-1))\n",
        "\n",
        "print(torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5]) * 8, dim=-1)) # gets too peaky, converges to one-hot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JB82yzt44REI",
        "outputId": "5a2dc891-575a-4cd6-dec1-722c81becdfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.1925, 0.1426, 0.2351, 0.1426, 0.2872])\n",
            "tensor([0.0326, 0.0030, 0.1615, 0.0030, 0.8000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This “masked, scaled, softmax weighted sum” is the core math of decoder self-attention.\n",
        "Next we'll use it to train a new bigram model."
      ],
      "metadata": {
        "id": "mTLpbcXq6KmM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalization in Transformers (LayerNorm)"
      ],
      "metadata": {
        "id": "gIuAPUWP6ehh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformers use **LayerNorm** (not BatchNorm) because it normalizes each token's feature vector independently.\n",
        "This works well for variable-length sequences and avoids batch-dependent behavior.\n",
        "\n",
        "**BatchNorm** normalizes each feature using statistics across the batch (and often time).\n",
        "**LayerNorm** normalizes each example (row) using statistics across its features.\n",
        "\n",
        "In Transformers we use **LayerNorm**."
      ],
      "metadata": {
        "id": "_wkhkOh5cnbU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# minimal LayerNorm implementation\n",
        "class LayerNorm1d:\n",
        "\n",
        "  def __init__(self, dim, eps=1e-5):\n",
        "    self.eps = eps\n",
        "    self.gamma = torch.ones(dim)\n",
        "    self.beta = torch.zeros(dim)\n",
        "\n",
        "  def __call__(self, x):\n",
        "    # forward pass: normalize each row (one example) across features\n",
        "    xmean = x.mean(1, keepdim=True)\n",
        "    xvar = x.var(1, keepdim=True, unbiased=False)\n",
        "    xhat = (x - xmean) / torch.sqrt(xvar + self.eps)\n",
        "    return self.gamma * xhat + self.beta\n",
        "\n",
        "  def parameters(self):\n",
        "    return [self.gamma, self.beta]"
      ],
      "metadata": {
        "id": "2Num7sX9CKOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test it\n",
        "module = LayerNorm1d(100)\n",
        "x = torch.randn(32, 100) # batch size 32 of 100-dimensional vectors\n",
        "\n",
        "x = module(x)\n",
        "print(x.shape)\n",
        "# print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXYyqFXFV6z0",
        "outputId": "c628e4fd-545d-4978-9f41-807305e27399"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# feature stats across batch (not guaranteed by LayerNorm)\n",
        "print(x[:, 0].mean(), x[:, 0].std())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "633T2cmnW1uk",
        "outputId": "c6da660a-81d4-4b59-a3b5-46b995905b6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0640) tensor(0.7472)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# per-sample stats across features (what LayerNorm enforces)\n",
        "print(x[0, :].mean(), x[0, :].std())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVtGXic172VP",
        "outputId": "c91aae7e-73d1-4040-c391-c4d2166fbd92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(4.7684e-09) tensor(1.0050)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LayerNorm makes each token's feature vector have stable scale.\n",
        "This helps attention + MLP layers train reliably."
      ],
      "metadata": {
        "id": "YqCzznag8JGX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bigram Language Model with Self-Attention"
      ],
      "metadata": {
        "id": "ZcvKeBXoZFOY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The original bigram model predicts the next token using only the current one.\n",
        "Here, we upgrade it by adding embeddings, positional information, and stacked self-attention blocks, turning it into a small Transformer-style language model."
      ],
      "metadata": {
        "id": "IFYr_x-T9aH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# training and model hyperparameters\n",
        "batch_size = 16 # sequences per batch\n",
        "block_size = 32 # context length\n",
        "max_iters = 5000\n",
        "eval_interval = 100\n",
        "learning_rate = 1e-3\n",
        "eval_iters = 200\n",
        "\n",
        "# model size\n",
        "n_embd = 64 # embedding dimension\n",
        "n_head = 4 # attention heads\n",
        "n_layer = 4 # transformer blocks\n",
        "dropout = 0.0\n",
        "\n",
        "# device\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "87xuPnCMXx31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "  # evaluate average loss on train and validation splits\n",
        "  out = {}\n",
        "  model.eval()\n",
        "\n",
        "  for split in ['train', 'val']:\n",
        "    losses = torch.zeros(eval_iters)\n",
        "    for k in range(eval_iters):\n",
        "      X, Y = get_batch(split)\n",
        "      X, Y = X.to(device), Y.to(device)\n",
        "      logits, loss = model(X, Y)\n",
        "      losses[k] = loss.item()\n",
        "    out[split] = losses.mean()\n",
        "\n",
        "  model.train()\n",
        "  return out\n",
        "\n",
        "class Head(nn.Module):\n",
        "  \"\"\"One causal self-attention head.\"\"\"\n",
        "\n",
        "  def __init__(self, head_size):\n",
        "    super().__init__()\n",
        "    self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "    self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "    self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "\n",
        "    # causal mask (not a parameter)\n",
        "    self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, x):\n",
        "    B,T,C = x.shape\n",
        "\n",
        "    k = self.key(x)   # (B, T, C)\n",
        "    q = self.query(x) # (B, T, C)\n",
        "\n",
        "    # scaled dot-product attention\n",
        "    wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
        "    wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
        "    wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
        "    wei = self.dropout(wei)\n",
        "\n",
        "    # weighted aggregation\n",
        "    v = self.value(x) # (B, T, C)\n",
        "    out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
        "\n",
        "    return out\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "  \"\"\"Multiple attention heads in parallel.\"\"\"\n",
        "\n",
        "  def __init__(self, num_heads, head_size):\n",
        "    super().__init__()\n",
        "    self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "    self.proj = nn.Linear(n_embd, n_embd)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # concatenate heads and project back\n",
        "    out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "    out = self.dropout(self.proj(out))\n",
        "    return out\n",
        "\n",
        "class FeedFoward(nn.Module):\n",
        "  \"\"\"Position-wise MLP.\"\"\"\n",
        "\n",
        "  def __init__(self, n_embd):\n",
        "    super().__init__()\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Linear(n_embd, 4 * n_embd),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(4 * n_embd, n_embd),\n",
        "        nn.Dropout(dropout),\n",
        "      )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.net(x)\n",
        "\n",
        "class Block(nn.Module):\n",
        "  \"\"\"Transformer block: Attention followed by computation.\"\"\"\n",
        "\n",
        "  def __init__(self, n_embd, n_head):\n",
        "    super().__init__()\n",
        "    head_size = n_embd // n_head\n",
        "    self.sa = MultiHeadAttention(n_head, head_size)\n",
        "    self.ffwd = FeedFoward(n_embd)\n",
        "    self.ln1 = nn.LayerNorm(n_embd)\n",
        "    self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # residual connections + pre-norm\n",
        "    x = x + self.sa(self.ln1(x))\n",
        "    x = x + self.ffwd(self.ln2(x))\n",
        "    return x\n",
        "\n",
        "class BigramLanguageModel(nn.Module):\n",
        "  \"\"\"Transformer-style autoregressive language model.\"\"\"\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # token and position embeddings\n",
        "    self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "    self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "\n",
        "    # transformer blocks\n",
        "    self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "\n",
        "    self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
        "    self.lm_head = nn.Linear(n_embd, vocab_size) # projection to vocab size\n",
        "\n",
        "  def forward(self, idx, targets=None):\n",
        "    B, T = idx.shape\n",
        "\n",
        "    tok_emb = self.token_embedding_table(idx) # (B, T, C)\n",
        "    pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T, C)\n",
        "\n",
        "    x = tok_emb + pos_emb # (B, T, C)\n",
        "    x = self.blocks(x) # (B, T, C)\n",
        "    x = self.ln_f(x) # (B, T, C)\n",
        "    logits = self.lm_head(x) # (B, T, vocab_size)\n",
        "\n",
        "    loss = None\n",
        "    if targets is not None:\n",
        "      B, T = targets.shape\n",
        "      logits = logits.view(B * T, logits.size(-1)) # last dim = vocab_size\n",
        "      targets = targets.view(B * T)\n",
        "      loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "    return logits, loss\n",
        "\n",
        "  def generate(self, idx, max_new_tokens):\n",
        "    for _ in range(max_new_tokens):\n",
        "      idx_cond = idx[:, -block_size:] # # crop context (to the last block_size tokens)\n",
        "      logits, loss = self(idx_cond)\n",
        "      logits = logits[:, -1, :] # last token\n",
        "      probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "      idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "      idx = torch.cat((idx, idx_next), dim=1) # (B, T + 1)\n",
        "    return idx"
      ],
      "metadata": {
        "id": "8F4UVSkaYfd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the model\n",
        "model = BigramLanguageModel()\n",
        "m = model.to(device)\n",
        "\n",
        "# number of parameters\n",
        "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fs_bA3XTBXOC",
        "outputId": "c4a91145-4ff3-434d-c942-f5337658085d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.209729 M parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for iter in range(max_iters):\n",
        "\n",
        "  # periodic evaluation\n",
        "  if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "    losses = estimate_loss()\n",
        "    print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "  xb, yb = get_batch('train')\n",
        "\n",
        "  # move batch to the same device as the model\n",
        "  xb, yb = xb.to(device), yb.to(device)\n",
        "\n",
        "  logits, loss = model(xb, yb)\n",
        "\n",
        "  optimizer.zero_grad(set_to_none=True)\n",
        "  loss.backward()\n",
        "  optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJQMyaUOYboF",
        "outputId": "e1464304-99dd-4c8e-e163-c26efb085736"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0: train loss 4.3478, val loss 4.3493\n",
            "step 100: train loss 2.6413, val loss 2.6349\n",
            "step 200: train loss 2.5119, val loss 2.4959\n",
            "step 300: train loss 2.4183, val loss 2.4009\n",
            "step 400: train loss 2.3519, val loss 2.3355\n",
            "step 500: train loss 2.3160, val loss 2.3115\n",
            "step 600: train loss 2.2693, val loss 2.2505\n",
            "step 700: train loss 2.2204, val loss 2.2142\n",
            "step 800: train loss 2.1657, val loss 2.1726\n",
            "step 900: train loss 2.1433, val loss 2.1419\n",
            "step 1000: train loss 2.1077, val loss 2.1031\n",
            "step 1100: train loss 2.0846, val loss 2.0855\n",
            "step 1200: train loss 2.0552, val loss 2.0803\n",
            "step 1300: train loss 2.0198, val loss 2.0265\n",
            "step 1400: train loss 2.0187, val loss 1.9980\n",
            "step 1500: train loss 1.9861, val loss 1.9839\n",
            "step 1600: train loss 1.9628, val loss 1.9560\n",
            "step 1700: train loss 1.9413, val loss 1.9347\n",
            "step 1800: train loss 1.9294, val loss 1.9307\n",
            "step 1900: train loss 1.9011, val loss 1.8965\n",
            "step 2000: train loss 1.8925, val loss 1.8882\n",
            "step 2100: train loss 1.8827, val loss 1.8737\n",
            "step 2200: train loss 1.8586, val loss 1.8741\n",
            "step 2300: train loss 1.8448, val loss 1.8580\n",
            "step 2400: train loss 1.8371, val loss 1.8452\n",
            "step 2500: train loss 1.8138, val loss 1.8169\n",
            "step 2600: train loss 1.8137, val loss 1.8111\n",
            "step 2700: train loss 1.7996, val loss 1.8018\n",
            "step 2800: train loss 1.7811, val loss 1.7883\n",
            "step 2900: train loss 1.7832, val loss 1.7706\n",
            "step 3000: train loss 1.7756, val loss 1.7680\n",
            "step 3100: train loss 1.7485, val loss 1.7602\n",
            "step 3200: train loss 1.7497, val loss 1.7535\n",
            "step 3300: train loss 1.7390, val loss 1.7276\n",
            "step 3400: train loss 1.7467, val loss 1.7502\n",
            "step 3500: train loss 1.7235, val loss 1.7221\n",
            "step 3600: train loss 1.7240, val loss 1.7211\n",
            "step 3700: train loss 1.7262, val loss 1.7089\n",
            "step 3800: train loss 1.7227, val loss 1.7284\n",
            "step 3900: train loss 1.7061, val loss 1.7017\n",
            "step 4000: train loss 1.7083, val loss 1.7010\n",
            "step 4100: train loss 1.7070, val loss 1.6966\n",
            "step 4200: train loss 1.6891, val loss 1.6927\n",
            "step 4300: train loss 1.6858, val loss 1.6832\n",
            "step 4400: train loss 1.6887, val loss 1.6846\n",
            "step 4500: train loss 1.6812, val loss 1.6715\n",
            "step 4600: train loss 1.6823, val loss 1.6767\n",
            "step 4700: train loss 1.6775, val loss 1.6741\n",
            "step 4800: train loss 1.6666, val loss 1.6667\n",
            "step 4900: train loss 1.6695, val loss 1.6635\n",
            "step 4999: train loss 1.6402, val loss 1.6576\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate text from the trained model\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "print(decode(m.generate(context, max_new_tokens=2000)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPwCVU--Z4q_",
        "outputId": "810afffd-1f26-460b-957a-ac58e5da9909"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Is time fits this seggains modistand heard:\n",
            "Therefore imploish beepapinish.\n",
            "IfI sakes and state her confain?\n",
            "This did atch the will posdeling.\n",
            "\n",
            "KING EDWARD IFI:\n",
            "He forch not shall he is will wull hich sends thou asters theee?\n",
            "This metter lesply?\n",
            "\n",
            "VOLUS:\n",
            "What woll!--follish he must lest brone\n",
            "down: a thou takely and ford priceptering;\n",
            "Let sons, my lundly for gods?\n",
            "\n",
            "Proyal, ban tell mine?\n",
            "\n",
            "LEONTES:\n",
            "what'snow this speak:\n",
            "Know my assure on my fair?\n",
            "\n",
            "QIEss tiver my lardshall and and barck duke not\n",
            "The son.\n",
            "\n",
            "KING RICHEbold my let from the spoys appon this\n",
            "Strock-stondlandled cargelands very your gone.\n",
            "\n",
            "WARLID IFILLIZEL:\n",
            "And this?\n",
            "\n",
            "WARWILK:\n",
            "Fortabant to the luck accusel leaven's will de'th.\n",
            "Now, A leaven'd shame hath I speech\n",
            "That I commannible-my spicks you woran,\n",
            "Be forthen this of old my lord frot myscans blons and in toerclesive.\n",
            "\n",
            "NFRORS MARUTIUS:\n",
            "\n",
            "PlENTER:\n",
            "Hy men. Engellars, what agoty, my doniesce.\n",
            "\n",
            "PARIAN:\n",
            "What barn thy king Caming;! anfull somembet quollif,\n",
            "Or him and watencous own To our grove:\n",
            "Now your much, the dothink my spubjectizer'd.\n",
            "\n",
            "First YORK:\n",
            "IrR I cournselverdendam, my wifeir. Hir command my breath.\n",
            "\n",
            "PRIARD:\n",
            "Khe's my had beand, and sleck the do dilink is of the forey\n",
            "Virting o' be it engod maisporiens:\n",
            "And not what are you? some!\n",
            "\n",
            "Fjoursen:\n",
            "I but madke reasuran tone;\n",
            "And well, boy disbous a down.\n",
            "\n",
            "ISABELLA:\n",
            "Pohalst he\n",
            "First such of To his the king cround was, it savise.\n",
            "\n",
            "LADY HENRY:\n",
            "My smeal there to be I reclay all,\n",
            "Butfalide yit my nor jown, To gorines.\n",
            "\n",
            "LADWERCIO:\n",
            "ReNswarding, years and not for a\n",
            "end coursing chepuaritin do sire\n",
            "Osk why forthousbider profooks myself,\n",
            "For him did cursing deliver, and torn;\n",
            "And wish on The she miskness very\n",
            "That me saken my fould all have me,\n",
            "Nothen, all proysings father upon the Romewixly.\n",
            "\n",
            "HORFORSIARD III:\n",
            "He her your loss might's pidisford,\n",
            "The quespress sadle deather, honself of undity.\n",
            "\n",
            "ESCALUS:\n",
            "Take they is his vontery, to my mean?\n",
            "To falsellovin that losalf frear diless\n",
            "Deck'd have to shame know old appeasur and\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model can now use context, position, and learned attention to make predictions. During training, we observe the loss steadily decreasing, which indicates that the model is learning meaningful patterns in the data.\n",
        "\n",
        "The generated text, while still far from fully consistent, already shows structure resembling Shakespeare-like dialogue. Its limitations come from the model's small size, short context window, character-level tokenization, and limited training time. Using subword or word-level tokens, along with larger models, longer contexts, and more training data, would significantly improve generation quality.\n"
      ],
      "metadata": {
        "id": "vWKJ4M4-98it"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We started with a minimal bigram model and incrementally added the core ideas behind Transformers.\n",
        "By building everything from scratch, we saw how attention replaces fixed averaging with learned, data-dependent communication between tokens.\n",
        "The same principles scale directly to large language models used in practice today."
      ],
      "metadata": {
        "id": "kwW_G4jR-Aet"
      }
    }
  ]
}